{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/25 18:47:34 WARN Utils: Your hostname, Tobiass-MacBook.local resolves to a loopback address: 127.0.0.1; using 10.27.90.105 instead (on interface en0)\n",
      "22/11/25 18:47:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/25 18:47:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/11/25 18:47:34 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import countDistinct\n",
    "sc=SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseude Code:\n",
    "\n",
    "agrupar por user, device, gt\n",
    "    para x, y, z sacar\n",
    "        median\n",
    "        desv\n",
    "        max\n",
    "        min\n",
    "\n",
    "join data from different datasets into RDDs\n",
    "Analize RDDs\n",
    "\n",
    "DonÂ´t repeat code!\n",
    "avoid many (unnecessary) lines of code / repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = [\"index\", \"arrival_time\", \"creation_time\", \"x\", \"y\", \"z\", \"user\", \"model\", \"device\", \"activity\"]\n",
    "\n",
    "pa = sc.textFile('Phones_accelerometer.csv')\n",
    "\n",
    "pg = sc.textFile('Phones_gyroscope.csv')\n",
    "\n",
    "wa = sc.textFile('Watch_accelerometer.csv')\n",
    "\n",
    "wg = sc.textFile('Watch_gyroscope.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a,gear,stand',\n",
       "  array([5047.        ,  111.77420486, -165.88138325, -360.541152  ,\n",
       "           29.48112279,   21.11171523,   38.46312038])),\n",
       " ('a,gear,null',\n",
       "  array([ 3.43000000e+02,  7.74154314e+00, -1.25568048e+01, -2.45913637e+01,\n",
       "          2.83401834e-01,  5.05536017e-01,  1.78524658e+00])),\n",
       " ('a,gear,sit',\n",
       "  array([4610.        ,  104.67288548, -190.95770893, -322.57645873,\n",
       "           17.37226198,   22.50625132,   32.00580686]))]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = wg.map(lambda x : x.split(\",\"))\n",
    "keyed = split.map(lambda x : (x[6] + \",\" + x[7]+ \",\" + x[9], np.array([1, float(x[3]), float(x[4]), float(x[5]), float(x[3])**2, float(x[4])**2, float(x[5])**2])))\n",
    "\n",
    "sum = keyed.reduceByKey(lambda x, y : x + y)\n",
    "std = sum.map(lambda x : (x[0], np.array([np.sqrt((x[1][4]/x[1][0])-(x[1][1]/x[1][0])**2), np.sqrt((x[1][5]/x[1][0])-(x[1][2]/x[1][0])**2), np.sqrt((x[1][6]/x[1][0])-(x[1][3]/x[1][0])**2)])))\n",
    "mean = sum.map(lambda x : (x[0], np.array((x[1][1]/x[1][0], x[1][2]/x[1][0], x[1][3]/x[1][0]))))\n",
    "\n",
    "#sum_std = keyed.map(lambda x: (x[1][1]  - mean[1][1])**2)\n",
    "'''std = sum_std.reduce(lambda x,y: x + y)\n",
    "std = np.sqrt(std/heights.count())'''\n",
    "\n",
    "sum.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in(filename):\n",
    "    #read in file and split at \",\"\n",
    "    rdd = sc.textFile(filename)\n",
    "    split_rdd = rdd.map(lambda x : x.split(\",\"))\n",
    "\n",
    "    #remove unnecessary variables, create primary key (user + model + gt), create floats: counter variable, x, y, z\n",
    "    keyed = split_rdd.map(lambda x : (x[6] + \",\" + x[7]+ \",\" + x[9], np.array([1, float(x[3]), float(x[4]), float(x[5])])))\n",
    "    return keyed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean(rdd):\n",
    "    # sum up numericals from input rdd --> x[1]: count per key, sum(x), sum(y), sum(z)\n",
    "    sum = rdd.reduceByKey(lambda x, y : x + y)\n",
    "    # divide sums by count\n",
    "    mean = sum.map(lambda x : (x[0], np.array((x[1][1]/x[1][0], x[1][2]/x[1][0], x[1][3]/x[1][0]))))\n",
    "\n",
    "    return mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_std(rdd):\n",
    "    #remove unnecessary variables, create primary key (user + model + gt), create floats: counter variable, x, y, z, x^2, y^2, z^2 \n",
    "    work_rdd = rdd.map(lambda x : (x[0], np.array([1, x[1][1], x[1][2], x[1][3], (x[1][1])**2, (x[1][2])**2, (x[1][3])**2])))\n",
    "\n",
    "    # sum up individual numerical values\n",
    "    sum = work_rdd.reduceByKey(lambda x, y : x + y)\n",
    "    # calculate std as follows: sqrt( (sum(x^2)/N) - (sum(x)/N)^2 )\n",
    "    std = sum.map(lambda x : (x[0], np.array([np.sqrt((x[1][4]/x[1][0])-(x[1][1]/x[1][0])**2), np.sqrt((x[1][5]/x[1][0])-(x[1][2]/x[1][0])**2), np.sqrt((x[1][6]/x[1][0])-(x[1][3]/x[1][0])**2)])))\n",
    "\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max(rdd):\n",
    "    max = rdd\n",
    "    return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = read_in('Watch_gyroscope.csv')\n",
    "\n",
    "work = out.map(lambda x: (x[0], x[1][1]))\n",
    "#out.reduceByKey(max).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min(rdd):\n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(filename):\n",
    "    rdd = read_in(filename)\n",
    "    mean = calc_mean(rdd)\n",
    "    std = calc_std(rdd)\n",
    "\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f5c7435bc3a0af7c2e50ff20f20879f4ae59d0d746704ca49b2ca7888dc9b87d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
